
## 结果分析

从结果中可以看出，使用不同特征提取与选择方法对最终的分类性能有显著影响。这里我们关注的是使用相同分类器（Logistic Regression，LR）时，不同特征降维或特征选择策略对模型性能的影响。对比指标包括：平均准确率(Accuracy)、平均F1分数(F1)、以及平均AUC值(AUC)，并且给出了其标准差(std)。

1. **PCA+LR**：  
   使用PCA进行降维后再用LR进行分类，平均准确率约为0.8218，F1约为0.7644，AUC为0.8550。整体来说，性能中规中矩。

2. **LassoSel+LR (Lasso特征选择)**：  
   使用Lasso进行特征选择再应用LR分类，准确率较PCA有提升(0.8397)，AUC也较高(0.9000)，说明Lasso选择的特征有助于提高模型区分度。

3. **RFE+LR (递归特征消除)**：  
   RFE策略下的LR表现也很不错，Accuracy为0.8385，F1为0.7884，AUC为0.8787。虽然AUC略低于Lasso，但F1分数更高，意味着在精确率与召回率的平衡上稍有优势。

4. **PLS+LR (偏最小二乘)**：  
   PLS方法下的LR表现最好，Accuracy达0.8526，F1为0.8070。在AUC为0.8613的情况下，这组结果整体表现均衡且优秀，是所有方法中最高的平均准确率和F1分数。

5. **Baseline LR (未做特征降维/选择)**：  
   基准模型（仅使用原始特征）在Accuracy为0.8051，F1为0.7623，AUC为0.8962的情况下表现不如PCA、Lasso、RFE、PLS几个有特征处理步骤的模型。这表明合理的特征工程有助于提升模型性能。

综合来看，PLS+LR组合在Accuracy和F1上表现最为突出，LassoSel+LR和RFE+LR在AUC和F1上也有各自的优势。若以整体指标均衡度来看，PLS+LR方案值得优先考虑。

## 各方法的Markdown对比表格

| 方法         | Accuracy(mean ± std) | F1(mean ± std)    | AUC(mean ± std)   |
|--------------|-----------------------|-------------------|-------------------|
| PCA+LR       | 0.8218 ± 0.0640      | 0.7644 ± 0.0862   | 0.8550 ± 0.0980   |
| LassoSel+LR  | 0.8397 ± 0.0706      | 0.7568 ± 0.1199   | 0.9000 ± 0.0977   |
| RFE+LR        | 0.8385 ± 0.0720      | 0.7884 ± 0.0945   | 0.8787 ± 0.0617   |
| PLS+LR       | 0.8526 ± 0.0651      | 0.8070 ± 0.0936   | 0.8613 ± 0.0891   |
| Baseline LR  | 0.8051 ± 0.0664      | 0.7623 ± 0.0909   | 0.8962 ± 0.0654   |

## RFE

- **RFE (Recursive Feature Elimination，递归特征消除)**：  
  是一种特征选择技术。其核心思想是先使用全部特征训练模型，然后根据特征重要性（如权重、系数大小）去除最不重要的特征，再重复这一过程，直到达到预定数量的特征。RFE通过迭代地消除不重要的特征，来保留对最终预测最有帮助的特征子集。
